{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of Movie Reviews with Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "def load_dataset(filename):\n",
    "    return pickle.load(open(filename, 'rb'))\n",
    "\n",
    "def create_vocab(docs):\n",
    "    vocab = []\n",
    "    for doc in docs:\n",
    "        vocab.extend(doc)\n",
    "    return vocab\n",
    "    \n",
    "def create_tokenizer(docs):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(docs)\n",
    "    return tokenizer\n",
    "\n",
    "def shuffle_data(X, y):\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X_y = np.concatenate((X, y[:, np.newaxis]), axis=1) \n",
    "    np.random.shuffle(X_y)\n",
    "    return X_y\n",
    "\n",
    "def define_model(input_shape):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Input(shape=(input_shape,)),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(loss='binary_crossentropy', optimizer = 'Adam', metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "def get_callbacks():\n",
    "    def scheduler(epoch, lr):\n",
    "        if epoch < 5:\n",
    "            return lr\n",
    "        else:\n",
    "            return lr*0.90\n",
    "    lr_scheduler_callback = tf.keras.callbacks.LearningRateScheduler(schedule=scheduler)\n",
    "    earlystopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                                                      min_delta=0,\n",
    "                                                      patience=20,\n",
    "                                                      mode='max',\n",
    "                                                      restore_best_weights=True)\n",
    "    return [lr_scheduler_callback, earlystopping_callback]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_39 (Dense)             (None, 256)               11817472  \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 11,860,481\n",
      "Trainable params: 11,859,585\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "None\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3078 - accuracy: 0.9000\n",
      "Test Accuracy:  89.99999761581421\n"
     ]
    }
   ],
   "source": [
    "train_docs, train_labels = load_dataset('movie_reviews_train.pkl')\n",
    "test_docs, test_labels = load_dataset('movie_reviews_test.pkl')\n",
    "docs = train_docs+test_docs\n",
    "tokenizer = create_tokenizer(docs)\n",
    "X_train = tokenizer.texts_to_matrix(train_docs, mode='binary')\n",
    "X_test = tokenizer.texts_to_matrix(test_docs, mode='binary')\n",
    "\n",
    "# Shuffle data\n",
    "train = shuffle_data(X_train, train_labels)\n",
    "test = shuffle_data(X_test, test_labels)\n",
    "\n",
    "# split train set in train and valid set\n",
    "train, valid = train[:1700], train[1700:]\n",
    "X_train, y_train = train[:, :-1], train[:, -1:]\n",
    "X_valid, y_valid = valid[:, :-1], valid[:, -1:]\n",
    "X_test, y_test = test[:, :-1], test[:, -1:]\n",
    "\n",
    "# obtain the model and fit it\n",
    "model = define_model(input_shape=X_train.shape[-1])\n",
    "call_backs = get_callbacks()\n",
    "model.fit(X_train, y_train, \n",
    "            epochs=100, \n",
    "            verbose=0, \n",
    "            validation_data=(X_valid, y_valid), \n",
    "            batch_size = 128, \n",
    "            callbacks=call_backs)\n",
    "model.save('model_movie_review_simpleNN.h5')\n",
    "print(model.summary())\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test Accuracy: ', accuracy*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def clean_doc(docs):\n",
    "    \"\"\" Removal of puntuations, stopwords, non-numerics\"\"\"\n",
    "    tokens = docs.split(' ')\n",
    "    # remove punctuations\n",
    "    reg_punctuation = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    tokens = [reg_punctuation.sub('', w) for w in tokens]\n",
    "    # romove numerics and stop words\n",
    "    tokens = [token for token in tokens if token.isalpha()]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if not word in stop_words]\n",
    "    return tokens\n",
    "\n",
    "def predict_sentiment(review, tokenizer, model, vocab):\n",
    "    tokens = clean_doc(review)\n",
    "    tokens = [w for w in tokens if w in vocab]\n",
    "    line = ' '.join(tokens)\n",
    "    encoded = tokenizer.texts_to_matrix([line], mode='binary')\n",
    "    y_pred = model.predict(encoded, verbose=0)\n",
    "    percent_pos = y_pred[0,0]\n",
    "    if round(percent_pos) == 0:\n",
    "        return  'NEGATIVE'\n",
    "    return  'POSITIVE'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_docs, _ = load_dataset('movie_reviews_train.pkl')\n",
    "test_docs, _ = load_dataset('movie_reviews_test.pkl')\n",
    "docs = train_docs+test_docs\n",
    "\n",
    "vocab = set([word for doc in docs for word in doc])\n",
    "\n",
    "text = \"\"\"It’s a piece on two of my favorite films of 2017, “Lady Bird” and\n",
    "        “Call Me By Your Name”, and about how their very different modes of storytelling \n",
    "        speak to the different sorts of stories we tell ourselves. Objectively, I don’t know \n",
    "        if this is my best work in terms of pure style and craft, but I do think it’s the most \n",
    "        emblematic in terms of what I value in cinema. I think every film is, in some way, \n",
    "        a treatise on how certain memories are remembered, and I think cinema matters \n",
    "        partly because the best examples of it are prisms through which the human experience \n",
    "        is refracted.Above everything else, every movie has to begin with a good story, and \n",
    "        the greatest stories are the ones that mirror not just life, but the ways in which \n",
    "        life is distorted and restructured through the process of remembering. Every aspect \n",
    "        of a film, from its screenplay on down, must add something to the film’s portrayal \n",
    "        of remembering, and “Lady Bird” and “Call Me By Your Name” accomplish this organic \n",
    "        unity of theme with such charm yet in such distinct ways, that they were the perfect \n",
    "        counterpoints to each other, as well as the perfect stand-ins for cinema as a whole, \n",
    "        for me.\"\"\"\n",
    "\n",
    "sentiment = predict_sentiment(text, tokenizer, model, vocab)\n",
    "print(sentiment,' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEGATIVE  \n"
     ]
    }
   ],
   "source": [
    "text =\"\"\"Judging by the movie's enduring popularity, the message that stupidity is \n",
    "        redemption is clearly what a lot of Americans want to hear.\"\"\"\n",
    "sentiment = predict_sentiment(text, tokenizer, model, vocab)\n",
    "print(sentiment,' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
